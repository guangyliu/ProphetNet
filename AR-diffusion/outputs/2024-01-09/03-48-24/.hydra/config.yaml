model:
  name: bert-base-uncased
  mode: s2s
  pretrain: null
exp:
  seed: 101
  root: ./my_output
  name: amazon
  dir: null
device: cuda
data:
  path: ./data
  name: amazon
time_channels: 128
in_channels: 128
out_channels: 128
diffusion_steps: 2000
tgt_len: 32
max_pos_len: 32
src_lang: de
tgt_lang: en
intermediate_size: 2048
num_attention_heads: 8
fairseq:
  use_fairseq: false
  real_data: false
  dist_data: false
vocab_size: 10000
use_mbert: false
use_bpe: false
pad_value: 0
num_workers: 4
lr_step: 40000
warmup_steps: 4000
total_steps: 80000
batch_size: 128
lr: 0.0008
weight_decay: 0.0
grad_clip: -1.0
ema_rate: 0.9999
grad_accum: 1
eval_interval: 3000
log_interval: 1000
save_interval: 10000
clip_scale: 0.0
use_step_ratio: false
ratio_thre: 0.7
label_smooth: 0.0
scale_embedding: false
continue_train: false
use_AMP: true
grad_penalty: false
loss_aware: false
pred_len: false
length_factor: 0.1
init_weight: false
prediction: false
pred_len_strategy: null
att_strategy: txl
rel_postion: false
position_att: false
time_att: true
infer_self_condition: false
self_condition: false
schedule_sampler: xy_uniform
end_point_scale: 2.0
dropout: 0.2
att_dropout: 0.1
num_samples: 1
ddim_sample: false
skip_timestep: 100
skip_sample: false
gen_timesteps: 20
predict_xstart: true
rescale_timesteps: true
resume_checkpoint: true
shared_embeds: false
roformer_timeAtt: false
add_layer_time: false
use_sentence_piece: false
load_encoder: false
predict_x_start: false
load_bart: false
use_kl: false
fix_encoder: false
learn_pos: false
sigma_small: false
learn_sigma: false
rescale_learned_sigmas: false
logits_mode: 1
noise_schedule: sqrt
emb_type: random
clip_denoised: false
load_from_ema: false
load_step: 0
mask_pro: 0.3
pre_max_len: 512
add_retrieval_sentences: false
retrieval_top_k: 1
